{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3_nlp2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO76bTlEOCwJ",
        "colab_type": "text"
      },
      "source": [
        "lab3_nlp2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YPQXd18XOgMG",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# lab3_nl2p.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCtHymfjOqxQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Predicting Movie Reviews with BERT on TF Hub.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
        "\n",
        " Copyright 2019 Google Inc.\n",
        " Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " you may not use this file except in compliance with the License.\n",
        " You may obtain a copy of the License at\n",
        "\n",
        "     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        " Unless required by applicable law or agreed to in writing, software\n",
        " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " See the License for the specific language governing permissions and\n",
        " limitations under the License.\n",
        "\n",
        "Predicting Movie Review Sentiment with BERT on TF Hub\n",
        "\n",
        "If you’ve been following Natural Language Processing over the past year, you’ve probably heard of BERT: Bidirectional Encoder Representations from Transformers. It’s a neural network architecture designed by Google researchers that’s totally transformed what’s state-of-the-art for NLP tasks, like text classification, translation, summarization, and question answering.\n",
        "\n",
        "Now that BERT's been added to [TF Hub](https://www.tensorflow.org/hub) as a loadable module, it's easy(ish) to add into existing Tensorflow text pipelines. In an existing pipeline, BERT can replace text embedding layers like ELMO and GloVE. Alternatively, [finetuning](http://wiki.fast.ai/index.php/Fine_tuning) BERT can provide both an accuracy boost and faster training time in many cases.\n",
        "\n",
        "Here, we'll train a model to predict whether an IMDB movie review is positive or negative using BERT in Tensorflow with tf hub. Some code was adapted from [this colab notebook](https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb). Let's get started!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exYC_22POdVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "60d76238-b8fe-4f13-9615-182569717a6a"
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "\n",
        "!rm -rf bert\n",
        "!git clone https://github.com/google-research/bert\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append('bert/')\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import codecs\n",
        "import collections\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import pprint\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import modeling\n",
        "import tokenization\n",
        "import run_classifier\n",
        "import optimization\n",
        "\n",
        "\n",
        "\"\"\"In addition to the standard libraries we imported above, we'll need to \n",
        "install BERT's python package.\n",
        "!pip install bert-tensorflow\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "\"\"\"\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0527 13:05:44.589041 139757240096640 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "Receiving objects:   0% (1/325)   \rReceiving objects:   1% (4/325)   \rReceiving objects:   2% (7/325)   \rReceiving objects:   3% (10/325)   \rReceiving objects:   4% (13/325)   \rReceiving objects:   5% (17/325)   \rReceiving objects:   6% (20/325)   \rReceiving objects:   7% (23/325)   \rReceiving objects:   8% (26/325)   \rReceiving objects:   9% (30/325)   \rReceiving objects:  10% (33/325)   \rReceiving objects:  11% (36/325)   \rReceiving objects:  12% (39/325)   \rReceiving objects:  13% (43/325)   \rReceiving objects:  14% (46/325)   \rReceiving objects:  15% (49/325)   \rReceiving objects:  16% (52/325)   \rReceiving objects:  17% (56/325)   \rReceiving objects:  18% (59/325)   \rReceiving objects:  19% (62/325)   \rReceiving objects:  20% (65/325)   \rReceiving objects:  21% (69/325)   \rReceiving objects:  22% (72/325)   \rReceiving objects:  23% (75/325)   \rReceiving objects:  24% (78/325)   \rReceiving objects:  25% (82/325)   \rReceiving objects:  26% (85/325)   \rReceiving objects:  27% (88/325)   \rReceiving objects:  28% (91/325)   \rReceiving objects:  29% (95/325)   \rReceiving objects:  30% (98/325)   \rReceiving objects:  31% (101/325)   \rReceiving objects:  32% (104/325)   \rReceiving objects:  33% (108/325)   \rReceiving objects:  34% (111/325)   \rReceiving objects:  35% (114/325)   \rReceiving objects:  36% (117/325)   \rReceiving objects:  37% (121/325)   \rReceiving objects:  38% (124/325)   \rReceiving objects:  39% (127/325)   \rReceiving objects:  40% (130/325)   \rReceiving objects:  41% (134/325)   \rReceiving objects:  42% (137/325)   \rReceiving objects:  43% (140/325)   \rReceiving objects:  44% (143/325)   \rReceiving objects:  45% (147/325)   \rReceiving objects:  46% (150/325)   \rReceiving objects:  47% (153/325)   \rReceiving objects:  48% (156/325)   \rReceiving objects:  49% (160/325)   \rReceiving objects:  50% (163/325)   \rReceiving objects:  51% (166/325)   \rReceiving objects:  52% (169/325)   \rReceiving objects:  53% (173/325)   \rReceiving objects:  54% (176/325)   \rReceiving objects:  55% (179/325)   \rReceiving objects:  56% (182/325)   \rReceiving objects:  57% (186/325)   \rReceiving objects:  58% (189/325)   \rReceiving objects:  59% (192/325)   \rReceiving objects:  60% (195/325)   \rReceiving objects:  61% (199/325)   \rReceiving objects:  62% (202/325)   \rReceiving objects:  63% (205/325)   \rReceiving objects:  64% (208/325)   \rReceiving objects:  65% (212/325)   \rReceiving objects:  66% (215/325)   \rReceiving objects:  67% (218/325)   \rReceiving objects:  68% (221/325)   \rReceiving objects:  69% (225/325)   \rReceiving objects:  70% (228/325)   \rReceiving objects:  71% (231/325)   \rReceiving objects:  72% (234/325)   \rReceiving objects:  73% (238/325)   \rReceiving objects:  74% (241/325)   \rReceiving objects:  75% (244/325)   \rReceiving objects:  76% (247/325)   \rremote: Total 325 (delta 0), reused 0 (delta 0), pack-reused 325\u001b[K\n",
            "Receiving objects:  77% (251/325)   \rReceiving objects:  78% (254/325)   \rReceiving objects:  79% (257/325)   \rReceiving objects:  80% (260/325)   \rReceiving objects:  81% (264/325)   \rReceiving objects:  82% (267/325)   \rReceiving objects:  83% (270/325)   \rReceiving objects:  84% (273/325)   \rReceiving objects:  85% (277/325)   \rReceiving objects:  86% (280/325)   \rReceiving objects:  87% (283/325)   \rReceiving objects:  88% (286/325)   \rReceiving objects:  89% (290/325)   \rReceiving objects:  90% (293/325)   \rReceiving objects:  91% (296/325)   \rReceiving objects:  92% (299/325)   \rReceiving objects:  93% (303/325)   \rReceiving objects:  94% (306/325)   \rReceiving objects:  95% (309/325)   \rReceiving objects:  96% (312/325)   \rReceiving objects:  97% (316/325)   \rReceiving objects:  98% (319/325)   \rReceiving objects:  99% (322/325)   \rReceiving objects: 100% (325/325)   \rReceiving objects: 100% (325/325), 232.46 KiB | 3.52 MiB/s, done.\n",
            "Resolving deltas:   0% (0/186)   \rResolving deltas:   1% (3/186)   \rResolving deltas:   2% (5/186)   \rResolving deltas:   5% (11/186)   \rResolving deltas:   7% (14/186)   \rResolving deltas:   8% (16/186)   \rResolving deltas:  12% (23/186)   \rResolving deltas:  15% (29/186)   \rResolving deltas:  22% (41/186)   \rResolving deltas:  23% (44/186)   \rResolving deltas:  32% (60/186)   \rResolving deltas:  74% (139/186)   \rResolving deltas:  76% (142/186)   \rResolving deltas:  83% (156/186)   \rResolving deltas:  84% (158/186)   \rResolving deltas:  87% (162/186)   \rResolving deltas:  91% (170/186)   \rResolving deltas:  94% (176/186)   \rResolving deltas: 100% (186/186)   \rResolving deltas: 100% (186/186), done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport bert\\nfrom bert import run_classifier\\nfrom bert import optimization\\nfrom bert import tokenization\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfYOBIOmP8mE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7759e5af-bdea-4e5e-fa38-f90e5735a22d"
      },
      "source": [
        "\n",
        "\"\"\"Below, we'll set an output directory location to store our model output and checkpoints. This can be a local directory, in which case you'd set OUTPUT_DIR to the name of the directory you'd like to create. If you're running this code in Google's hosted Colab, the directory won't persist after the Colab session ends.\n",
        "\n",
        "Alternatively, if you're a GCP user, you can store output in a GCP bucket. To do that, set a directory name in OUTPUT_DIR and the name of the GCP bucket in the BUCKET field.\n",
        "\n",
        "Set DO_DELETE to rewrite the OUTPUT_DIR if it exists. Otherwise, Tensorflow will load existing model checkpoints from that directory (if they exist).\n",
        "\"\"\"\n",
        "\n",
        "# Set the output directory for saving model file\n",
        "# Optionally, set a GCP bucket location\n",
        "\n",
        "OUTPUT_DIR = 'bert0'#@param {type:\"string\"}\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = False #@param {type:\"boolean\"}\n",
        "#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n",
        "USE_BUCKET = False #@param {type:\"boolean\"}\n",
        "BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\n",
        "\n",
        "if USE_BUCKET:\n",
        "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    # Doesn't matter if the directory didn't exist\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: bert0 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NT-FYlhO_G_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1abe6969-0f13-4c08-fab0-bb67e4887b9d"
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"#Data\n",
        "\n",
        "First, let's download the dataset, hosted by Stanford. The code below, \n",
        "which downloads, extracts, and imports the IMDB Large Movie Review Dataset,\n",
        "is borrowed from [this Tensorflow tutorial](https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub).\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df\n",
        "\n",
        "train, test = download_and_load_datasets()\n",
        "\n",
        "\"\"\"To keep training fast, we'll take a sample of 5000 train and test examples,\n",
        "respectively.\"\"\"\n",
        "\n",
        "train = train.sample(5000)\n",
        "test = test.sample(5000)\n",
        "\n",
        "train.columns\n",
        "\n",
        "\"\"\"For us, our input data is the 'sentence' column and our label is the \n",
        "'polarity' column (0, 1 for negative and positive, respecitvely)\"\"\"\n",
        "\n",
        "DATA_COLUMN = 'sentence'\n",
        "LABEL_COLUMN = 'polarity'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [0, 1]\n",
        "\n",
        "\"\"\"#Data Preprocessing\n",
        "We'll need to transform our data into a format BERT understands. This\n",
        "involves two steps. First, we create  `InputExample`'s using the constructor\n",
        "provided in the BERT library.\n",
        "\n",
        "- `text_a` is the text we want to classify, which in this case, is the\n",
        "`Request` field in our Dataframe. \n",
        "- `text_b` is used if we're training a model to understand the relationship\n",
        "between sentences (i.e. is `text_b` a translation of `text_a`? Is \n",
        "`text_b` an answer to the question asked by `text_a`?). This doesn't\n",
        "apply to our task, so we can leave `text_b` blank.\n",
        "- `label` is the label for our example, i.e. True, False\n",
        "\"\"\"\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"#Data Preprocessing\\nWe'll need to transform our data into a format BERT understands. This\\ninvolves two steps. First, we create  `InputExample`'s using the constructor\\nprovided in the BERT library.\\n\\n- `text_a` is the text we want to classify, which in this case, is the\\n`Request` field in our Dataframe. \\n- `text_b` is used if we're training a model to understand the relationship\\nbetween sentences (i.e. is `text_b` a translation of `text_a`? Is \\n`text_b` an answer to the question asked by `text_a`?). This doesn't\\napply to our task, so we can leave `text_b` blank.\\n- `label` is the label for our example, i.e. True, False\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z95MLfNzRBgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "            text_a = x[DATA_COLUMN], \n",
        "            text_b = None, \n",
        "            label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: run_classifier.InputExample(guid=None, \n",
        "            text_a = x[DATA_COLUMN], \n",
        "            text_b = None, \n",
        "            label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4_jz4RZSIaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2621
        },
        "outputId": "c7d5c840-e0a1-48da-c1a9-791e65befcbf"
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"Next, we need to preprocess our data so that it matches the data BERT was trained on. For this, we'll need to do a couple of things (but don't worry--this is also included in the Python library):\n",
        "\n",
        "\n",
        "1. Lowercase our text (if we're using a BERT lowercase model)\n",
        "2. Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
        "3. Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
        "4. Map our words to indexes using a vocab file that BERT provides\n",
        "5. Add special \"CLS\" and \"SEP\" tokens (see the [readme](https://github.com/google-research/bert))\n",
        "6. Append \"index\" and \"segment\" tokens to each input (see the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
        "\n",
        "Happily, we don't have to worry about most of these details.\n",
        "\n",
        "To start, we'll need to load a vocabulary file and lowercasing information directly from the BERT tf hub module:\n",
        "\"\"\"\n",
        "\n",
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()\n",
        "\n",
        "\"\"\"Great--we just learned that the BERT model we're using expects lowercase data \n",
        "(that's what stored in tokenization_info[\"do_lower_case\"]) and we also\n",
        "loaded BERT's vocab file. We also created a tokenizer, which breaks words\n",
        "into word pieces:\"\"\"\n",
        "\n",
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")\n",
        "\n",
        "\"\"\"Using our tokenizer, we'll call `run_classifier.convert_examples_to_features`\n",
        "on our InputExamples to convert them into features BERT understands.\"\"\"\n",
        "\n",
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = run_classifier.convert_examples_to_features(\n",
        "    train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = run_classifier.convert_examples_to_features(\n",
        "\n",
        "    test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0527 13:07:40.602292 139757240096640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:42.825060 139757240096640 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.483568 139757240096640 run_classifier.py:774] Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.506236 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.509577 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] as with most of the reviewers , i saw this on star ##z ! on ##de ##man ##d . after watching the preview with my girlfriend , she decided not to watch it from how bad the preview watched . i , on the other hand , thought it looked weird enough to warrant a watching . i mean , the design of dr . me ##so alone warrant ##ed at least a brief sweep over this title . after watching it , i can say that while there are some interesting aspects to it ( namely the brows ##ing over the notebook ##s and trying to figure out the inc ##omp ##re ##hen ##sible story ) , it ' s best to pass over this [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.513714 139757240096640 run_classifier.py:464] tokens: [CLS] as with most of the reviewers , i saw this on star ##z ! on ##de ##man ##d . after watching the preview with my girlfriend , she decided not to watch it from how bad the preview watched . i , on the other hand , thought it looked weird enough to warrant a watching . i mean , the design of dr . me ##so alone warrant ##ed at least a brief sweep over this title . after watching it , i can say that while there are some interesting aspects to it ( namely the brows ##ing over the notebook ##s and trying to figure out the inc ##omp ##re ##hen ##sible story ) , it ' s best to pass over this [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2004 2007 2087 1997 1996 15814 1010 1045 2387 2023 2006 2732 2480 999 2006 3207 2386 2094 1012 2044 3666 1996 19236 2007 2026 6513 1010 2016 2787 2025 2000 3422 2009 2013 2129 2919 1996 19236 3427 1012 1045 1010 2006 1996 2060 2192 1010 2245 2009 2246 6881 2438 2000 10943 1037 3666 1012 1045 2812 1010 1996 2640 1997 2852 1012 2033 6499 2894 10943 2098 2012 2560 1037 4766 11740 2058 2023 2516 1012 2044 3666 2009 1010 1045 2064 2360 2008 2096 2045 2024 2070 5875 5919 2000 2009 1006 8419 1996 11347 2075 2058 1996 14960 2015 1998 2667 2000 3275 2041 1996 4297 25377 2890 10222 19307 2466 1007 1010 2009 1005 1055 2190 2000 3413 2058 2023 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.518305 139757240096640 run_classifier.py:465] input_ids: 101 2004 2007 2087 1997 1996 15814 1010 1045 2387 2023 2006 2732 2480 999 2006 3207 2386 2094 1012 2044 3666 1996 19236 2007 2026 6513 1010 2016 2787 2025 2000 3422 2009 2013 2129 2919 1996 19236 3427 1012 1045 1010 2006 1996 2060 2192 1010 2245 2009 2246 6881 2438 2000 10943 1037 3666 1012 1045 2812 1010 1996 2640 1997 2852 1012 2033 6499 2894 10943 2098 2012 2560 1037 4766 11740 2058 2023 2516 1012 2044 3666 2009 1010 1045 2064 2360 2008 2096 2045 2024 2070 5875 5919 2000 2009 1006 8419 1996 11347 2075 2058 1996 14960 2015 1998 2667 2000 3275 2041 1996 4297 25377 2890 10222 19307 2466 1007 1010 2009 1005 1055 2190 2000 3413 2058 2023 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.521541 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.525310 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.528647 139757240096640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.534255 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.537409 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] simply put , this is the best movie to come out of michigan since . . . well , ever ! evil dead eat your heart out , hatred of a minute was some of the odd ##est , and best cinema to be seen by this reviewer in a long time . i recommend this movie to anyone who is in need of a head trip , or a good case of the willie ##s ! [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.540393 139757240096640 run_classifier.py:464] tokens: [CLS] simply put , this is the best movie to come out of michigan since . . . well , ever ! evil dead eat your heart out , hatred of a minute was some of the odd ##est , and best cinema to be seen by this reviewer in a long time . i recommend this movie to anyone who is in need of a head trip , or a good case of the willie ##s ! [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3432 2404 1010 2023 2003 1996 2190 3185 2000 2272 2041 1997 4174 2144 1012 1012 1012 2092 1010 2412 999 4763 2757 4521 2115 2540 2041 1010 11150 1997 1037 3371 2001 2070 1997 1996 5976 4355 1010 1998 2190 5988 2000 2022 2464 2011 2023 12027 1999 1037 2146 2051 1012 1045 16755 2023 3185 2000 3087 2040 2003 1999 2342 1997 1037 2132 4440 1010 2030 1037 2204 2553 1997 1996 9893 2015 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.543315 139757240096640 run_classifier.py:465] input_ids: 101 3432 2404 1010 2023 2003 1996 2190 3185 2000 2272 2041 1997 4174 2144 1012 1012 1012 2092 1010 2412 999 4763 2757 4521 2115 2540 2041 1010 11150 1997 1037 3371 2001 2070 1997 1996 5976 4355 1010 1998 2190 5988 2000 2022 2464 2011 2023 12027 1999 1037 2146 2051 1012 1045 16755 2023 3185 2000 3087 2040 2003 1999 2342 1997 1037 2132 4440 1010 2030 1037 2204 2553 1997 1996 9893 2015 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.546776 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.549862 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.552854 139757240096640 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.574145 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.577268 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the mor ##bid catholic writer gerard rev ##e ( je ##ro ##en k ##ra ##bbe ) that is homosexual , alcoholic and has frequent visions of death is invited to give a lecture in the literature club of v ##lis ##sing ##en . while in the railway station in amsterdam , he feels a non - corresponded attraction to a handsome man that embark ##s in another train . gerard is introduced to the treasurer of the club and beau ##tic ##ian christine hal ##ss ##lag ( renee so ##ute ##ndi ##jk ) , who is a wealthy widow that owns the beauty shop sphinx , and they have one night stand . on the next morning , gerard sees the picture of christine ' s [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.580789 139757240096640 run_classifier.py:464] tokens: [CLS] the mor ##bid catholic writer gerard rev ##e ( je ##ro ##en k ##ra ##bbe ) that is homosexual , alcoholic and has frequent visions of death is invited to give a lecture in the literature club of v ##lis ##sing ##en . while in the railway station in amsterdam , he feels a non - corresponded attraction to a handsome man that embark ##s in another train . gerard is introduced to the treasurer of the club and beau ##tic ##ian christine hal ##ss ##lag ( renee so ##ute ##ndi ##jk ) , who is a wealthy widow that owns the beauty shop sphinx , and they have one night stand . on the next morning , gerard sees the picture of christine ' s [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 22822 17062 3234 3213 11063 7065 2063 1006 15333 3217 2368 1047 2527 19473 1007 2008 2003 15667 1010 14813 1998 2038 6976 12018 1997 2331 2003 4778 2000 2507 1037 8835 1999 1996 3906 2252 1997 1058 6856 7741 2368 1012 2096 1999 1996 2737 2276 1999 7598 1010 2002 5683 1037 2512 1011 27601 8432 2000 1037 8502 2158 2008 28866 2015 1999 2178 3345 1012 11063 2003 3107 2000 1996 10211 1997 1996 2252 1998 17935 4588 2937 10941 11085 4757 17802 1006 17400 2061 10421 16089 15992 1007 1010 2040 2003 1037 7272 7794 2008 8617 1996 5053 4497 27311 1010 1998 2027 2031 2028 2305 3233 1012 2006 1996 2279 2851 1010 11063 5927 1996 3861 1997 10941 1005 1055 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.583541 139757240096640 run_classifier.py:465] input_ids: 101 1996 22822 17062 3234 3213 11063 7065 2063 1006 15333 3217 2368 1047 2527 19473 1007 2008 2003 15667 1010 14813 1998 2038 6976 12018 1997 2331 2003 4778 2000 2507 1037 8835 1999 1996 3906 2252 1997 1058 6856 7741 2368 1012 2096 1999 1996 2737 2276 1999 7598 1010 2002 5683 1037 2512 1011 27601 8432 2000 1037 8502 2158 2008 28866 2015 1999 2178 3345 1012 11063 2003 3107 2000 1996 10211 1997 1996 2252 1998 17935 4588 2937 10941 11085 4757 17802 1006 17400 2061 10421 16089 15992 1007 1010 2040 2003 1037 7272 7794 2008 8617 1996 5053 4497 27311 1010 1998 2027 2031 2028 2305 3233 1012 2006 1996 2279 2851 1010 11063 5927 1996 3861 1997 10941 1005 1055 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.586739 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.590145 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.592491 139757240096640 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.600671 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.602866 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] great movie - i loved it . great editing and use of the soundtrack . captures the real feeling of indian life , yet we can all relate . a well chose cast with some great characters . the movie develops all the characters so that you real care about them all and you feel like you know them . the use of the indian music and drums in some of the soccer scenes is great and the direction really works as everyone comes off as real and natural . you just can ' t help but to root for jess in this film ! the acting was really good , even the tomb ##oy ##ish walk and body posture of both leading ladies is very [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.606664 139757240096640 run_classifier.py:464] tokens: [CLS] great movie - i loved it . great editing and use of the soundtrack . captures the real feeling of indian life , yet we can all relate . a well chose cast with some great characters . the movie develops all the characters so that you real care about them all and you feel like you know them . the use of the indian music and drums in some of the soccer scenes is great and the direction really works as everyone comes off as real and natural . you just can ' t help but to root for jess in this film ! the acting was really good , even the tomb ##oy ##ish walk and body posture of both leading ladies is very [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2307 3185 1011 1045 3866 2009 1012 2307 9260 1998 2224 1997 1996 6050 1012 19566 1996 2613 3110 1997 2796 2166 1010 2664 2057 2064 2035 14396 1012 1037 2092 4900 3459 2007 2070 2307 3494 1012 1996 3185 11791 2035 1996 3494 2061 2008 2017 2613 2729 2055 2068 2035 1998 2017 2514 2066 2017 2113 2068 1012 1996 2224 1997 1996 2796 2189 1998 3846 1999 2070 1997 1996 4715 5019 2003 2307 1998 1996 3257 2428 2573 2004 3071 3310 2125 2004 2613 1998 3019 1012 2017 2074 2064 1005 1056 2393 2021 2000 7117 2005 12245 1999 2023 2143 999 1996 3772 2001 2428 2204 1010 2130 1996 8136 6977 4509 3328 1998 2303 16819 1997 2119 2877 6456 2003 2200 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.613145 139757240096640 run_classifier.py:465] input_ids: 101 2307 3185 1011 1045 3866 2009 1012 2307 9260 1998 2224 1997 1996 6050 1012 19566 1996 2613 3110 1997 2796 2166 1010 2664 2057 2064 2035 14396 1012 1037 2092 4900 3459 2007 2070 2307 3494 1012 1996 3185 11791 2035 1996 3494 2061 2008 2017 2613 2729 2055 2068 2035 1998 2017 2514 2066 2017 2113 2068 1012 1996 2224 1997 1996 2796 2189 1998 3846 1999 2070 1997 1996 4715 5019 2003 2307 1998 1996 3257 2428 2573 2004 3071 3310 2125 2004 2613 1998 3019 1012 2017 2074 2064 1005 1056 2393 2021 2000 7117 2005 12245 1999 2023 2143 999 1996 3772 2001 2428 2204 1010 2130 1996 8136 6977 4509 3328 1998 2303 16819 1997 2119 2877 6456 2003 2200 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.616868 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.621525 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.625504 139757240096640 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.643249 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.647411 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] what boo ##b at mgm thought it would be a good idea to place the stud ##ly clark gable in the role of a salvation army worker ? ? ironically enough , another handsome future star , cary grant , also played a salvation army guy just two years later in the highly over ##rated she done him wrong . i guess in hind ##sight it ' s pretty easy to see the folly of these roles , but i still wonder who thought that salvation army guys are \" hot \" and who could look at these dash ##ing men and see them as realistic representations of the parts they played . a long time ago , i used to work for a sister organization [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.651366 139757240096640 run_classifier.py:464] tokens: [CLS] what boo ##b at mgm thought it would be a good idea to place the stud ##ly clark gable in the role of a salvation army worker ? ? ironically enough , another handsome future star , cary grant , also played a salvation army guy just two years later in the highly over ##rated she done him wrong . i guess in hind ##sight it ' s pretty easy to see the folly of these roles , but i still wonder who thought that salvation army guys are \" hot \" and who could look at these dash ##ing men and see them as realistic representations of the parts they played . a long time ago , i used to work for a sister organization [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2054 22017 2497 2012 15418 2245 2009 2052 2022 1037 2204 2801 2000 2173 1996 16054 2135 5215 13733 1999 1996 2535 1997 1037 12611 2390 7309 1029 1029 18527 2438 1010 2178 8502 2925 2732 1010 20533 3946 1010 2036 2209 1037 12611 2390 3124 2074 2048 2086 2101 1999 1996 3811 2058 9250 2016 2589 2032 3308 1012 1045 3984 1999 17666 25807 2009 1005 1055 3492 3733 2000 2156 1996 26272 1997 2122 4395 1010 2021 1045 2145 4687 2040 2245 2008 12611 2390 4364 2024 1000 2980 1000 1998 2040 2071 2298 2012 2122 11454 2075 2273 1998 2156 2068 2004 12689 15066 1997 1996 3033 2027 2209 1012 1037 2146 2051 3283 1010 1045 2109 2000 2147 2005 1037 2905 3029 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.655851 139757240096640 run_classifier.py:465] input_ids: 101 2054 22017 2497 2012 15418 2245 2009 2052 2022 1037 2204 2801 2000 2173 1996 16054 2135 5215 13733 1999 1996 2535 1997 1037 12611 2390 7309 1029 1029 18527 2438 1010 2178 8502 2925 2732 1010 20533 3946 1010 2036 2209 1037 12611 2390 3124 2074 2048 2086 2101 1999 1996 3811 2058 9250 2016 2589 2032 3308 1012 1045 3984 1999 17666 25807 2009 1005 1055 3492 3733 2000 2156 1996 26272 1997 2122 4395 1010 2021 1045 2145 4687 2040 2245 2008 12611 2390 4364 2024 1000 2980 1000 1998 2040 2071 2298 2012 2122 11454 2075 2273 1998 2156 2068 2004 12689 15066 1997 1996 3033 2027 2209 1012 1037 2146 2051 3283 1010 1045 2109 2000 2147 2005 1037 2905 3029 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.659954 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.662861 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:07:43.666211 139757240096640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.483784 139757240096640 run_classifier.py:774] Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.493512 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.496396 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] \" a texas community is be ##set with a rash of mysterious killings involving some of the students from the local college . the sheriff investigating the death discovers the startling identity of the killer responsible for the murders . a nasa experiment involving cosmic rays has mu ##tated an ape and turned it into an un ##sto ##ppa ##ble killing machine with a thirst for blood , \" according to the dvd sleeve ' s syn ##opsis . < br / > < br / > or , could the creature really be a mu ##tated alligator returning from a space - bound \" noah ' s ark \" ? < br / > < br / > a long opening , with laugh ##ably [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.498203 139757240096640 run_classifier.py:464] tokens: [CLS] \" a texas community is be ##set with a rash of mysterious killings involving some of the students from the local college . the sheriff investigating the death discovers the startling identity of the killer responsible for the murders . a nasa experiment involving cosmic rays has mu ##tated an ape and turned it into an un ##sto ##ppa ##ble killing machine with a thirst for blood , \" according to the dvd sleeve ' s syn ##opsis . < br / > < br / > or , could the creature really be a mu ##tated alligator returning from a space - bound \" noah ' s ark \" ? < br / > < br / > a long opening , with laugh ##ably [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1000 1037 3146 2451 2003 2022 13462 2007 1037 23438 1997 8075 16431 5994 2070 1997 1996 2493 2013 1996 2334 2267 1012 1996 6458 11538 1996 2331 9418 1996 19828 4767 1997 1996 6359 3625 2005 1996 9916 1012 1037 9274 7551 5994 14448 9938 2038 14163 16238 2019 23957 1998 2357 2009 2046 2019 4895 16033 13944 3468 4288 3698 2007 1037 21810 2005 2668 1010 1000 2429 2000 1996 4966 10353 1005 1055 19962 22599 1012 1026 7987 1013 1028 1026 7987 1013 1028 2030 1010 2071 1996 6492 2428 2022 1037 14163 16238 28833 4192 2013 1037 2686 1011 5391 1000 7240 1005 1055 15745 1000 1029 1026 7987 1013 1028 1026 7987 1013 1028 1037 2146 3098 1010 2007 4756 8231 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.499875 139757240096640 run_classifier.py:465] input_ids: 101 1000 1037 3146 2451 2003 2022 13462 2007 1037 23438 1997 8075 16431 5994 2070 1997 1996 2493 2013 1996 2334 2267 1012 1996 6458 11538 1996 2331 9418 1996 19828 4767 1997 1996 6359 3625 2005 1996 9916 1012 1037 9274 7551 5994 14448 9938 2038 14163 16238 2019 23957 1998 2357 2009 2046 2019 4895 16033 13944 3468 4288 3698 2007 1037 21810 2005 2668 1010 1000 2429 2000 1996 4966 10353 1005 1055 19962 22599 1012 1026 7987 1013 1028 1026 7987 1013 1028 2030 1010 2071 1996 6492 2428 2022 1037 14163 16238 28833 4192 2013 1037 2686 1011 5391 1000 7240 1005 1055 15745 1000 1029 1026 7987 1013 1028 1026 7987 1013 1028 1037 2146 3098 1010 2007 4756 8231 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.501436 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.504165 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.507714 139757240096640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.521964 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.523954 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] who else other than tr ##oma can take the classic tragedy and change it around to today ##s standards ? ? ? ? no one . . . . in my opinion the leonardo di ##cap ##rio one sucked . tr ##ome ##on & juliet is a definite stretch from the original shakes ##per ##an tragedy , but it holds up well . its sick , dem ##ented , twisted , but yet insane ##ly funny and fulfilling . for the most part it follows the true romeo and juliet story , but many tr ##oma elements are added . will keenan gives a great performance as tr ##ome ##o . the acting is solid and the story is great . many people look past these [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.526721 139757240096640 run_classifier.py:464] tokens: [CLS] who else other than tr ##oma can take the classic tragedy and change it around to today ##s standards ? ? ? ? no one . . . . in my opinion the leonardo di ##cap ##rio one sucked . tr ##ome ##on & juliet is a definite stretch from the original shakes ##per ##an tragedy , but it holds up well . its sick , dem ##ented , twisted , but yet insane ##ly funny and fulfilling . for the most part it follows the true romeo and juliet story , but many tr ##oma elements are added . will keenan gives a great performance as tr ##ome ##o . the acting is solid and the story is great . many people look past these [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2040 2842 2060 2084 19817 9626 2064 2202 1996 4438 10576 1998 2689 2009 2105 2000 2651 2015 4781 1029 1029 1029 1029 2053 2028 1012 1012 1012 1012 1999 2026 5448 1996 14720 4487 17695 9488 2028 8631 1012 19817 8462 2239 1004 13707 2003 1037 15298 7683 2013 1996 2434 10854 4842 2319 10576 1010 2021 2009 4324 2039 2092 1012 2049 5305 1010 17183 14088 1010 6389 1010 2021 2664 9577 2135 6057 1998 21570 1012 2005 1996 2087 2112 2009 4076 1996 2995 12390 1998 13707 2466 1010 2021 2116 19817 9626 3787 2024 2794 1012 2097 26334 3957 1037 2307 2836 2004 19817 8462 2080 1012 1996 3772 2003 5024 1998 1996 2466 2003 2307 1012 2116 2111 2298 2627 2122 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.528858 139757240096640 run_classifier.py:465] input_ids: 101 2040 2842 2060 2084 19817 9626 2064 2202 1996 4438 10576 1998 2689 2009 2105 2000 2651 2015 4781 1029 1029 1029 1029 2053 2028 1012 1012 1012 1012 1999 2026 5448 1996 14720 4487 17695 9488 2028 8631 1012 19817 8462 2239 1004 13707 2003 1037 15298 7683 2013 1996 2434 10854 4842 2319 10576 1010 2021 2009 4324 2039 2092 1012 2049 5305 1010 17183 14088 1010 6389 1010 2021 2664 9577 2135 6057 1998 21570 1012 2005 1996 2087 2112 2009 4076 1996 2995 12390 1998 13707 2466 1010 2021 2116 19817 9626 3787 2024 2794 1012 2097 26334 3957 1037 2307 2836 2004 19817 8462 2080 1012 1996 3772 2003 5024 1998 1996 2466 2003 2307 1012 2116 2111 2298 2627 2122 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.531694 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.537033 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.539916 139757240096640 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.551032 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.553193 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] one would think that a film based on the life of the japanese author yuki ##o mis ##hima would be a da ##unt ##ing if not impossible task . however paul sc ##hra ##der has indeed made a film \" about \" mis ##hima that is both superb & complex . while it is not a literal biography , sc ##hra ##der & his co - screenwriter leonard sc ##hard ##er ( his brother ) have taken several incidents from his life , including his su ##cide and crafted what can best be described as incident ##al table ##aus that are visually sparse and stunning . mis ##hima ' s homosexuality is almost not there , due to legal threats from his widow , but in [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.555801 139757240096640 run_classifier.py:464] tokens: [CLS] one would think that a film based on the life of the japanese author yuki ##o mis ##hima would be a da ##unt ##ing if not impossible task . however paul sc ##hra ##der has indeed made a film \" about \" mis ##hima that is both superb & complex . while it is not a literal biography , sc ##hra ##der & his co - screenwriter leonard sc ##hard ##er ( his brother ) have taken several incidents from his life , including his su ##cide and crafted what can best be described as incident ##al table ##aus that are visually sparse and stunning . mis ##hima ' s homosexuality is almost not there , due to legal threats from his widow , but in [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2028 2052 2228 2008 1037 2143 2241 2006 1996 2166 1997 1996 2887 3166 24924 2080 28616 16369 2052 2022 1037 4830 16671 2075 2065 2025 5263 4708 1012 2174 2703 8040 13492 4063 2038 5262 2081 1037 2143 1000 2055 1000 28616 16369 2008 2003 2119 21688 1004 3375 1012 2096 2009 2003 2025 1037 18204 8308 1010 8040 13492 4063 1004 2010 2522 1011 11167 7723 8040 11783 2121 1006 2010 2567 1007 2031 2579 2195 10444 2013 2010 2166 1010 2164 2010 10514 27082 1998 19275 2054 2064 2190 2022 2649 2004 5043 2389 2795 20559 2008 2024 17453 20288 1998 14726 1012 28616 16369 1005 1055 15949 2003 2471 2025 2045 1010 2349 2000 3423 8767 2013 2010 7794 1010 2021 1999 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.558618 139757240096640 run_classifier.py:465] input_ids: 101 2028 2052 2228 2008 1037 2143 2241 2006 1996 2166 1997 1996 2887 3166 24924 2080 28616 16369 2052 2022 1037 4830 16671 2075 2065 2025 5263 4708 1012 2174 2703 8040 13492 4063 2038 5262 2081 1037 2143 1000 2055 1000 28616 16369 2008 2003 2119 21688 1004 3375 1012 2096 2009 2003 2025 1037 18204 8308 1010 8040 13492 4063 1004 2010 2522 1011 11167 7723 8040 11783 2121 1006 2010 2567 1007 2031 2579 2195 10444 2013 2010 2166 1010 2164 2010 10514 27082 1998 19275 2054 2064 2190 2022 2649 2004 5043 2389 2795 20559 2008 2024 17453 20288 1998 14726 1012 28616 16369 1005 1055 15949 2003 2471 2025 2045 1010 2349 2000 3423 8767 2013 2010 7794 1010 2021 1999 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.565415 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.567356 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.571854 139757240096640 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.578521 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.584171 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the acting is excellent in this film , with some great actors . it was fun to see fred mc ##mur ##ray as a young man . this is not a comedy . it ' s a drama and the apparently comedic instances are pit ##iful . this is not a comedy . it ' s a drama and the apparently comedic instances are pit ##iful , and some of them appear forced and con ##tri ##ved . it ' s in the script , though , not the fault of the acting . < br / > < br / > the 10 line requirement forces me to write some more . . . hmm ##m . loved carole lombard ' s my man godfrey [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.587460 139757240096640 run_classifier.py:464] tokens: [CLS] the acting is excellent in this film , with some great actors . it was fun to see fred mc ##mur ##ray as a young man . this is not a comedy . it ' s a drama and the apparently comedic instances are pit ##iful . this is not a comedy . it ' s a drama and the apparently comedic instances are pit ##iful , and some of them appear forced and con ##tri ##ved . it ' s in the script , though , not the fault of the acting . < br / > < br / > the 10 line requirement forces me to write some more . . . hmm ##m . loved carole lombard ' s my man godfrey [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3772 2003 6581 1999 2023 2143 1010 2007 2070 2307 5889 1012 2009 2001 4569 2000 2156 5965 11338 20136 9447 2004 1037 2402 2158 1012 2023 2003 2025 1037 4038 1012 2009 1005 1055 1037 3689 1998 1996 4593 21699 12107 2024 6770 18424 1012 2023 2003 2025 1037 4038 1012 2009 1005 1055 1037 3689 1998 1996 4593 21699 12107 2024 6770 18424 1010 1998 2070 1997 2068 3711 3140 1998 9530 18886 7178 1012 2009 1005 1055 1999 1996 5896 1010 2295 1010 2025 1996 6346 1997 1996 3772 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2184 2240 9095 2749 2033 2000 4339 2070 2062 1012 1012 1012 17012 2213 1012 3866 24348 23441 1005 1055 2026 2158 18238 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.592128 139757240096640 run_classifier.py:465] input_ids: 101 1996 3772 2003 6581 1999 2023 2143 1010 2007 2070 2307 5889 1012 2009 2001 4569 2000 2156 5965 11338 20136 9447 2004 1037 2402 2158 1012 2023 2003 2025 1037 4038 1012 2009 1005 1055 1037 3689 1998 1996 4593 21699 12107 2024 6770 18424 1012 2023 2003 2025 1037 4038 1012 2009 1005 1055 1037 3689 1998 1996 4593 21699 12107 2024 6770 18424 1010 1998 2070 1997 2068 3711 3140 1998 9530 18886 7178 1012 2009 1005 1055 1999 1996 5896 1010 2295 1010 2025 1996 6346 1997 1996 3772 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2184 2240 9095 2749 2033 2000 4339 2070 2062 1012 1012 1012 17012 2213 1012 3866 24348 23441 1005 1055 2026 2158 18238 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.596144 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.599484 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.604682 139757240096640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.616205 139757240096640 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.619487 139757240096640 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] simply i just watched this movie just because of sarah & am also giving these 4 stars just because of her , on the other side this movie was easily one of the worst movies i have ever seen . the ##act ##ing was horrible . the script was un ##ins ##pired . this was a movie that kept contra ##dict ##ing itself . the film was sloppy and uno ##ri ##ginal . its not like i was expecting a good film . just something to give me a jump or two . this did not even do that . < br / > < br / > he worst thing is that , the more i think about the overall plot , the less sense [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.621941 139757240096640 run_classifier.py:464] tokens: [CLS] simply i just watched this movie just because of sarah & am also giving these 4 stars just because of her , on the other side this movie was easily one of the worst movies i have ever seen . the ##act ##ing was horrible . the script was un ##ins ##pired . this was a movie that kept contra ##dict ##ing itself . the film was sloppy and uno ##ri ##ginal . its not like i was expecting a good film . just something to give me a jump or two . this did not even do that . < br / > < br / > he worst thing is that , the more i think about the overall plot , the less sense [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3432 1045 2074 3427 2023 3185 2074 2138 1997 4532 1004 2572 2036 3228 2122 1018 3340 2074 2138 1997 2014 1010 2006 1996 2060 2217 2023 3185 2001 4089 2028 1997 1996 5409 5691 1045 2031 2412 2464 1012 1996 18908 2075 2001 9202 1012 1996 5896 2001 4895 7076 21649 1012 2023 2001 1037 3185 2008 2921 24528 29201 2075 2993 1012 1996 2143 2001 28810 1998 27776 3089 24965 1012 2049 2025 2066 1045 2001 8074 1037 2204 2143 1012 2074 2242 2000 2507 2033 1037 5376 2030 2048 1012 2023 2106 2025 2130 2079 2008 1012 1026 7987 1013 1028 1026 7987 1013 1028 2002 5409 2518 2003 2008 1010 1996 2062 1045 2228 2055 1996 3452 5436 1010 1996 2625 3168 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.625213 139757240096640 run_classifier.py:465] input_ids: 101 3432 1045 2074 3427 2023 3185 2074 2138 1997 4532 1004 2572 2036 3228 2122 1018 3340 2074 2138 1997 2014 1010 2006 1996 2060 2217 2023 3185 2001 4089 2028 1997 1996 5409 5691 1045 2031 2412 2464 1012 1996 18908 2075 2001 9202 1012 1996 5896 2001 4895 7076 21649 1012 2023 2001 1037 3185 2008 2921 24528 29201 2075 2993 1012 1996 2143 2001 28810 1998 27776 3089 24965 1012 2049 2025 2066 1045 2001 8074 1037 2204 2143 1012 2074 2242 2000 2507 2033 1037 5376 2030 2048 1012 2023 2106 2025 2130 2079 2008 1012 1026 7987 1013 1028 1026 7987 1013 1028 2002 5409 2518 2003 2008 1010 1996 2062 1045 2228 2055 1996 3452 5436 1010 1996 2625 3168 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.628087 139757240096640 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.630860 139757240096640 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:10.633194 139757240096640 run_classifier.py:468] label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCup6ZueRYgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "225c0002-df21-47d7-fe54-dd8b0d83edc6"
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"#Creating a model\n",
        "\n",
        "Now that we've prepared our data, let's focus on building a model.\n",
        "`create_model` does just this below. First, it loads the BERT tf\n",
        "hub module again (this time to extract the computation graph).\n",
        "Next, it creates a single new layer that will be trained to adapt BERT \n",
        "to our sentiment task (i.e. classifying whether a movie review is \n",
        "positive or negative). This strategy of using a mostly trained model \n",
        "is called [fine-tuning](http://wiki.fast.ai/index.php/Fine_tuning).\n",
        "\"\"\"\n",
        "\n",
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n",
        "\n",
        "\"\"\"Next we'll wrap our model function in a `model_fn_builder` function that \n",
        "adapts our model to work for training, evaluation, and prediction.\"\"\"\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n",
        "\n",
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "\n",
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})\n",
        "\n",
        "\"\"\"Next we create an input builder function that takes our training feature set (`train_features`) and produces a generator. This is a pretty standard design pattern for working with Tensorflow [Estimators](https://www.tensorflow.org/guide/estimators).\"\"\"\n",
        "\n",
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)\n",
        "\n",
        "\"\"\"Now we train our model! For me, using a Colab notebook running on Google's\n",
        "GPUs, my training time was about 14 minutes.\"\"\"\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'bert0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1b7e6935f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:08:52.314161 139757240096640 estimator.py:201] Using config: {'_model_dir': 'bert0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1b7e6935f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Now we train our model! For me, using a Colab notebook running on Google's\\nGPUs, my training time was about 14 minutes.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmkaSPutZNra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1227
        },
        "outputId": "523cd292-7238-4785-bd7b-c7df9cd1cfaf"
      },
      "source": [
        "\n",
        "\n",
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:09:04.599845 139757240096640 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:09:07.950111 139757240096640 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-3ae63f565c4f>:47: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0527 13:09:08.090862 139757240096640 deprecation.py:506] From <ipython-input-6-3ae63f565c4f>:47: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0527 13:09:08.142363 139757240096640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0527 13:09:08.236835 139757240096640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0527 13:09:17.460424 139757240096640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:09:18.798507 139757240096640 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:09:18.805979 139757240096640 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:09:22.967493 139757240096640 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0527 13:09:22.970812 139757240096640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from bert0/model.ckpt-0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:09:22.979394 139757240096640 saver.py:1270] Restoring parameters from bert0/model.ckpt-0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0527 13:09:34.382104 139757240096640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:09:34.928727 139757240096640 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:09:35.261353 139757240096640 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into bert0/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:09:46.510717 139757240096640 basic_session_run_hooks.py:594] Saving checkpoints for 0 into bert0/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.7691344, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 13:10:46.788367 139757240096640 basic_session_run_hooks.py:249] loss = 0.7691344, step = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0220635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 14:26:19.153298 139757240096640 basic_session_run_hooks.py:680] global_step/sec: 0.0220635\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.6038867, step = 101 (4532.371 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0527 14:26:19.159367 139757240096640 basic_session_run_hooks.py:247] loss = 0.6038867, step = 101 (4532.371 sec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrSIKXqlZPnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"Now let's use our test data to see how well our model did:\"\"\"\n",
        "\n",
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n",
        "\n",
        "estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "\n",
        "\"\"\"Now let's write code to make predictions on new sentences:\"\"\"\n",
        "\n",
        "def getPrediction(in_sentences):\n",
        "  labels = [\"Negative\", \"Positive\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]\n",
        "\n",
        "pred_sentences = [\n",
        "  \"That movie was absolutely awful\",\n",
        "  \"The acting was a bit lacking\",\n",
        "  \"The film was creative and surprising\",\n",
        "  \"Absolutely fantastic!\"\n",
        "]\n",
        "\n",
        "predictions = getPrediction(pred_sentences)\n",
        "\n",
        "\"\"\"Voila! We have a sentiment classifier!\"\"\"\n",
        "\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv-T1KmYOJjY",
        "colab_type": "text"
      },
      "source": [
        "end notebook"
      ]
    }
  ]
}